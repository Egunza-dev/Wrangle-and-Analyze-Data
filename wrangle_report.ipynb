{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Using both visual and programmatic assessment of twitter-archive-enhanced.csv and tweet-json.txt datasets I identified quality and tidiness issues that required cleaning to make analysis possible.\n",
    "The following listing documents the issues identified along with steps taken to clean the data:\n",
    "### Quality Issues\n",
    "a. `twitter-archive-enhanced.csv` - missing data in the following columns(expanded_urls, retweeted_status_timestamp, retweeted_status_user_id, retweeted_status_id, in_reply_to_user_id, in_reply_to_status_id).\n",
    "- I used the dataframe drop method to delete the columns with missing values in df_twitter_archive_copy.\n",
    "```python\n",
    "    df_twitter_archive_copy.drop(['expanded_urls', 'retweeted_status_timestamp', 'retweeted_status_user_id', 'retweeted_status_id', 'in_reply_to_user_id', 'in_reply_to_status_id'], axis='columns', inplace=True)\n",
    "```\n",
    "\n",
    "\n",
    "b. `twitter-archive-enhanced.csv` - timestamp column has incorrect data type of object instead of datatime data type.\n",
    "- I used pandas to_datetime method to change the data type of timestamp column to datetime.\n",
    "```python\n",
    "   df_twitter_archive_copy['timestamp']=pd.to_datetime(df_twitter_archive_copy['timestamp'])\n",
    "```\n",
    "\n",
    "\n",
    "c. `twitter-archive-enhanced.csv` - 23 instances where incorrect 'rating_denominator' exist\n",
    "- I extracted the text variable of each of the 23 records to determine the correct rating.\n",
    "- If the rating was impossible to determine from the text then I deleted record.\n",
    "- Assigning the appropriate rating_numerator & rating_denominator variables from the text variables:\n",
    "```python\n",
    "    #313 @jonnysun @Lin_Manuel ok jomny I know you're excited but 960/00 isn't a valid rating, 13/10 is tho\n",
    "df_twitter_archive_copy.at[313, 'rating_numerator']= 13\n",
    "df_twitter_archive_copy.at[313, 'rating_denominator']= 10\n",
    "```\n",
    "```python\n",
    "#784 RT @dog_rates: After so many requests, this is Bretagne. She was the last surviving 9/11 \n",
    "search dog, and our second ever 14/10. RIP https:/â€¦\n",
    "df_twitter_archive_copy.at[784, 'rating_numerator']= 14\n",
    "df_twitter_archive_copy.at[784, 'rating_denominator']= 10\n",
    "```\n",
    "```python\n",
    "#1165 Happy 4/20 from the squad! 13/10 for all https://t.co/eV1diwds8a\n",
    "df_twitter_archive_copy.at[1165, 'rating_numerator']= 13\n",
    "df_twitter_archive_copy.at[1165, 'rating_denominator']= 10\n",
    "```\n",
    "```python\n",
    "#202 This is Bluebert. He just saw that both #FinalFur match ups are split 50/50. Amazed \n",
    "#af. 11/10 https://t.co/Kky1DPG4iq\n",
    "df_twitter_archive_copy.at[1202, 'rating_numerator']= 11\n",
    "df_twitter_archive_copy.at[1202, 'rating_denominator']= 10\n",
    "```\n",
    "```python\n",
    "#1662 This is Darrel. He just robbed a 7/11 and is in a high speed police chase. Was \n",
    "#just spotted by the helicopter 10/10 https://t.co/7EsP8LmSp5\n",
    "df_twitter_archive_copy.at[1662, 'rating_numerator']= 10\n",
    "df_twitter_archive_copy.at[1662, 'rating_denominator']= 10\n",
    "```\n",
    "```python\n",
    "#2335 This is an Albanian 3 1/2 legged  Episcopalian. Loves well-polished hardwood flooring. Penis on the collar. 9/10 https://t.co/d9NcXFKwLv\n",
    "df_twitter_archive_copy.at[2335, 'rating_numerator']= 9\n",
    "df_twitter_archive_copy.at[2335, 'rating_denominator']= 10\n",
    "```\n",
    "\n",
    "- Deleting records that rate_numerator variable cann't be extracted from the text variable:\n",
    "```python\n",
    "    df_twitter_archive_copy.drop([1843, 1663, 1635, 1634, 1598, 1433, 1351, 1274, 1254, 1228, 1120, 902, 516, 433, 342, 1068, 1779], axis='rows', inplace=True)\n",
    "```\n",
    "\n",
    "\n",
    "d. `twitter-archive-enhanced.csv` - 9 records had inappropriate rating_numerator variables i.e greater than 20 after correcting the rating_denominator issue.\n",
    "- I deleted the 9 records with inappropriate rating_numerator variables\n",
    "```python\n",
    "    df_twitter_archive_copy.drop([1695, 759, 973, 188, 187, 2055, 289, 339, 691], axis='rows', inplace=True)\n",
    "```\n",
    "\n",
    "\n",
    "e. `twitter-archive-enhanced.csv` - some records have more than one dog stage.\n",
    "Retrieve the text variables of records with more than on dog stage and determine the correct dog stage\n",
    "- I retrieved the text variables of records with more than on dog stage and determined the correct dog stage\n",
    "```python\n",
    "    df_twitter_archive_copy[((df_twitter_archive_copy['doggo']=='doggo') & (df_twitter_archive_copy['Dog Stage'] != 'doggo'))].index\n",
    "```\n",
    "```python\n",
    "    df_twitter_archive_copy[((df_twitter_archive_copy['floofer']=='floofer') & (df_twitter_archive_copy['Dog Stage'] != 'floofer'))].index\n",
    "```\n",
    "```python\n",
    "    df_twitter_archive_copy[((df_twitter_archive_copy['puppo']=='puppo') & (df_twitter_archive_copy['Dog Stage'] != 'puppo'))].index\n",
    "```\n",
    "```python\n",
    "    df_twitter_archive_copy[((df_twitter_archive_copy['pupper']=='pupper') & (df_twitter_archive_copy['Dog Stage'] != 'pupper'))].index\n",
    "```\n",
    "\n",
    "f. `tweet-json.txt` - quoted_status, quoted_status_id_str columns contain same duplicated values.\n",
    "- I deleted quoted_status_id_str column\n",
    "```python\n",
    "    df_tweet_json_copy.drop(['quoted_status_id_str'], axis='columns', inplace=True)\n",
    "```\n",
    "\n",
    "\n",
    "g. `tweet-json.txt` - missing data in the following columns(in_reply_to_status_id, in_reply_to_status_id_str, in_reply_to_user_id, in_reply_to_user_id_str, in_reply_to_screen_name, user, geo, coordinates, place, contributors, quoted_status, quoted_status_id, retweeted_status, possibly_sensitive_appealable, possibly_sensitive).\n",
    "- I deleted columns with missing values in tweet_json data.\n",
    "```python\n",
    "    df_tweet_json_copy.drop(['in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'quoted_status', 'quoted_status_id_str',  'quoted_status_id', 'retweeted_status', 'possibly_sensitive_appealable', 'possibly_sensitive'], axis='columns', inplace=True)\n",
    "```\n",
    "\n",
    "\n",
    "h. `tweet-json.txt` - id, id_str columns contain same values in 1518 instances - duplicated\n",
    "- I deleted id_str column in the tweet_json data.\n",
    "```python\n",
    "    df_tweet_json_copy.drop(['id_str'], axis='columns', inplace=True)\n",
    "```\n",
    "\n",
    "\n",
    "### Tidiness issues\n",
    "\n",
    "i. `twitter-archive-enhanced.csv` - doggo, floofer, pupper, puppo are values of the 'dog stage' variable and are being used as columns.\n",
    "- I created a new column 'Dog Stage' and populated it using values in doggo, floofer, pupper, puppo columns then delete doggo, floofer, pupper, puppo columns\n",
    "```python\n",
    "    df_twitter_archive_copy['Dog Stage'] = np.nan\n",
    "    max_row = df_twitter_archive_copy.shape[0]\n",
    "    for i in range(0, max_row):\n",
    "        if df_twitter_archive_copy.iloc[i]['doggo'] == 'doggo':\n",
    "            df_twitter_archive_copy.at[i, 'Dog Stage']= 'doggo'\n",
    "        elif df_twitter_archive_copy.iloc[i]['floofer'] == 'floofer':\n",
    "            df_twitter_archive_copy.at[i, 'Dog Stage']= 'floofer'\n",
    "        elif df_twitter_archive_copy.iloc[i]['pupper'] == 'pupper':\n",
    "            df_twitter_archive_copy.at[i, 'Dog Stage']= 'pupper'\n",
    "        elif df_twitter_archive_copy.iloc[i]['puppo'] == 'puppo':\n",
    "            df_twitter_archive_copy.at[i, 'Dog Stage']= 'puppo'\n",
    "```\n",
    "```python\n",
    "    df_twitter_archive_copy.drop(['doggo', 'floofer', 'pupper', 'puppo'], axis='columns', inplace=True)\n",
    "```\n",
    "\n",
    "j. `twitter-archive-enhanced.csv and tweet-json.txt` - duplicated columns in the tables(source, in_reply_to_status_id, in_reply_to_user_id). Other columns are duplicated but have different identifiers(created_at and timestamp, full_text and text)\n",
    "I deleted the duplicated columns in tweet_json data (source, in_reply_to_status_id, created_at, in_reply_to_user_id, full_text).\n",
    "```python\n",
    "    df_tweet_json_copy.drop(['source', 'created_at', 'full_text'], axis='columns', inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
